#!/usr/bin/env python3
"""
DeepRSM Training Script for CTM Data

This script uses a kernelized tensor with shape (5,2,288,600,1200) (5 molecules, 2 scenarios, 288 timesteps, 600×1200 grid)
and processes it as follows:
  - Rearranges the data so that the 2 scenarios are concatenated to form 10 channels.
  - Downsamples the data to a 75×150 grid.
  - Applies a log1p transform.
  - Generates synthetic targets: 14 polynomial coefficients are generated by applying a fixed linear mapping
    to the global average of the indicator maps.
  - Splits the data into 80% training, 10% validation, and 10% test.
  - Creates sliding-window sequences (context window = 24 timesteps; forecast horizon = 1) where the input is the full 10‑channel image and the target is the 5th channel.
  - Trains a DeepRSM-style CNN (with residual blocks, dropout, and weight decay) to predict the 14 coefficients.
  - Uses a dynamic learning rate scheduler that linearly warms up to a max LR and then decays following a cosine curve over the remaining epochs.
  - Plots learning curves and for 5 selected test samples, creates bar charts comparing the ground-truth vs. predicted coefficients.
"""

import os
import math
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import mean_squared_error
from matplotlib.colors import LogNorm

# ----------------------------
# Basic Hyperparameters
# ----------------------------
base_lr      = 3e-3
weight_decay = 1e-4
out_channels = 14   # Number of polynomial coefficients
warmup_ratio = 0.2
num_epochs   = 200
batch_size   = 32

# ----------------------------
# Device Configuration
# ----------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
torch.cuda.empty_cache()

# Current directory
current_dir = os.getcwd()

# ----------------------------
# Load Kernelized Tensor Data
# ----------------------------
super_tensor_file = os.path.join(current_dir, "kernelized_tensor.npy")
molecule_types = ["CH4", "CO2", "CO2bio", "GWP", "N2O"]
data_types = ["emi", "flx"]
super_tensor_shape = (5, 2, 288, 600, 1200)
kernelized_tensor = np.memmap(super_tensor_file, dtype="float32", mode="r", shape=super_tensor_shape)
print("Loaded data shape:", kernelized_tensor.shape)

# ----------------------------
# Data Preprocessing
# ----------------------------
# Concatenate the 2 scenarios along the channel dimension:
# Transpose to (288,600,1200,2,5) then reshape to (288,600,1200,10)
Y_temp = np.transpose(kernelized_tensor, (2, 3, 4, 1, 0))  # shape: (288,600,1200,2,5)
Y_full = Y_temp.reshape(288, 600, 1200, 10)  # Now each timestep has 10 channels

# Downsample from 600×1200 to 75×150 using block averaging (8×8 blocks)
num_time = 288
target_h, target_w = 75, 150
Y_low = np.empty((num_time, target_h, target_w, 10), dtype=np.float32)
for i in range(num_time):
    Y_low[i] = Y_full[i].reshape(target_h, 8, target_w, 8, 10).mean(axis=(1,3))

# Apply log1p transformation
Y_low_log = np.log1p(Y_low)  # shape: (288, 75, 150, 10)

# ----------------------------
# Generate Synthetic Target Coefficients
# ----------------------------
np.random.seed(42)
W_fixed = np.random.randn(10, 14).astype(np.float32)
b_fixed = np.random.randn(14).astype(np.float32)
def generate_targets(X):
    avg = X.mean(axis=(1,2))  # shape: (T,10)
    return avg @ W_fixed + b_fixed  # shape: (T,14)
Y_coeff = generate_targets(Y_low_log)  # shape: (288,14)

# ----------------------------
# Split into Train/Val/Test (80/10/10)
# ----------------------------
T_total = Y_low_log.shape[0]
train_size = int(0.8 * T_total)       # ~230 samples
val_size   = int(0.1 * T_total)       # ~29 samples
test_size  = T_total - train_size - val_size  # ~29 samples

X_data = Y_low_log  # Each sample: (75,150,10)
Y_data = Y_coeff    # Each sample: (14,)

X_train = X_data[:train_size]
Y_train = Y_data[:train_size]
X_val   = X_data[train_size:train_size+val_size]
Y_val   = Y_data[train_size:train_size+val_size]
X_test  = X_data[train_size+val_size:]
Y_test  = Y_data[train_size+val_size:]

print("Dataset shapes:")
print("Train X:", X_train.shape, "Train Y:", Y_train.shape)
print("Val X:", X_val.shape, "Val Y:", Y_val.shape)
print("Test X:", X_test.shape, "Test Y:", Y_test.shape)

# ----------------------------
# Convert to Tensors
# ----------------------------
# For CNN, expected input shape is (batch, channels, H, W).
X_train_t = torch.tensor(X_train.transpose(0,3,1,2), dtype=torch.float32, device=device)
Y_train_t = torch.tensor(Y_train, dtype=torch.float32, device=device)
X_val_t   = torch.tensor(X_val.transpose(0,3,1,2), dtype=torch.float32, device=device)
Y_val_t   = torch.tensor(Y_val, dtype=torch.float32, device=device)
X_test_t  = torch.tensor(X_test.transpose(0,3,1,2), dtype=torch.float32, device=device)
Y_test_t  = torch.tensor(Y_test, dtype=torch.float32, device=device)

train_dataset = TensorDataset(X_train_t, Y_train_t)
train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# ----------------------------
# Define the DeepRSM Model (CNN with Residual Blocks)
# ----------------------------
class BasicBlock(nn.Module):
    def __init__(self, channels):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)
        self.relu  = nn.LeakyReLU(negative_slope=0.1)
        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)
    def forward(self, x):
        identity = x
        out = self.conv1(x)
        out = self.relu(out)
        out = self.conv2(out)
        return self.relu(out + identity)

class DeepRSM(nn.Module):
    def __init__(self, in_ch=10, out_ch=14, hidden_ch=128, num_blocks=8):
        super(DeepRSM, self).__init__()
        self.initial = nn.Conv2d(in_ch, hidden_ch, kernel_size=3, padding=1)
        self.relu = nn.LeakyReLU(negative_slope=0.1)
        self.blocks = nn.Sequential(*[BasicBlock(hidden_ch) for _ in range(num_blocks)])
        self.final = nn.Conv2d(hidden_ch, out_ch, kernel_size=1)
        self.pool = nn.AdaptiveAvgPool2d((1,1))
    def forward(self, x):
        x = self.initial(x)
        x = self.relu(x)
        x = self.blocks(x)
        x = self.final(x)
        x = self.pool(x)
        x = x.view(x.size(0), -1)
        return x

model = DeepRSM(in_ch=10, out_ch=14, hidden_ch=128, num_blocks=8).to(device)
def init_weights(m):
    if isinstance(m, nn.Conv2d):
        nn.init.kaiming_normal_(m.weight, nonlinearity='leaky_relu')
        if m.bias is not None:
            nn.init.zeros_(m.bias)
model.apply(init_weights)

criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=base_lr, weight_decay=weight_decay)

# Dynamic LR: linear warmup (first 20% epochs) then cosine decay (first half period: from base_lr to 0)
warmup_epochs = int(warmup_ratio * num_epochs)
def lr_lambda(epoch):
    if epoch < warmup_epochs:
        # Linear warmup from 0 to 1
        return epoch / float(warmup_epochs)
    else:
        # progress from 0..1 after warmup
        progress = (epoch - warmup_epochs) / float(num_epochs - warmup_epochs)
        # Cosine half-wave from 1..0
        return 0.5 * (np.cos(np.pi * progress) + 1)
scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)

print(model)

# ----------------------------
# Training Loop
# ----------------------------
train_losses = []
val_losses = []
for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0.0
    for batch_X, batch_Y in train_loader:
        optimizer.zero_grad()
        preds = model(batch_X)  # (batch, 14)
        loss = criterion(preds, batch_Y)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item() * batch_X.size(0)
    epoch_loss /= len(train_dataset)
    train_losses.append(epoch_loss)
    
    # Validation evaluation (normal testing)
    model.eval()
    with torch.no_grad():
        val_preds = model(X_val_t)  # (N_val, 14)
        val_loss = criterion(val_preds, Y_val_t).item()
    val_losses.append(val_loss)
    
    scheduler.step()
    current_lr = optimizer.param_groups[0]['lr']
    if (epoch + 1) % 10 == 0:
        print(f"Epoch {epoch+1}/{num_epochs}, LR={current_lr:.2e}, Train MSE={epoch_loss:.6f}, Val MSE={val_loss:.6f}")

# ----------------------------
# Test Evaluation
# ----------------------------
model.eval()
with torch.no_grad():
    test_preds = model(X_test_t)  # (N_test, 14)
test_loss = criterion(test_preds, Y_test_t).item()
print("Test MSE (normalized):", test_loss)

test_preds_np = test_preds.cpu().numpy()
Y_test_np = Y_test_t.cpu().numpy()
test_mse_final = mean_squared_error(Y_test_np, test_preds_np)
print("Test MSE (final):", test_mse_final)

# ----------------------------
# Plot LR, Train, and Validation Loss Curves
# ----------------------------
epochs_arr = np.arange(1, num_epochs+1)
lr_list = []
for ep in range(num_epochs):
    if ep < warmup_epochs:
        factor = ep / float(warmup_epochs)
    else:
        factor = np.cos((ep - warmup_epochs) * np.pi / (2 * (num_epochs - warmup_epochs)))
    lr_list.append(base_lr * factor)

plt.figure(figsize=(8,6))
plt.subplot(2,1,1)
plt.plot(epochs_arr, np.log(train_losses), label='Log Train MSE')
plt.plot(epochs_arr, np.log(val_losses), label='Log Val MSE')
plt.xlabel('Epoch')
plt.ylabel('Log MSE')
plt.legend()
plt.title('Train/Val MSE')

plt.subplot(2,1,2)
plt.plot(epochs_arr, lr_list, label='Learning Rate')
plt.xlabel('Epoch')
plt.ylabel('LR')
plt.title('Dynamic Learning Rate')
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(current_dir, "train_val_mse_and_lr.png"), dpi=300)
plt.show()

# ----------------------------
# Plot Specific Coefficient Comparisons for Selected Test Samples
# ----------------------------
def plot_coefficients_comparison(gt_coeffs, pred_coeffs, sample_idx):
    fig, ax = plt.subplots(figsize=(8,4))
    x = np.arange(out_channels)
    ax.bar(x - 0.2, gt_coeffs, width=0.4, label='Ground Truth', alpha=0.7)
    ax.bar(x + 0.2, pred_coeffs, width=0.4, label='Prediction', alpha=0.7)
    ax.set_xticks(x)
    ax.set_xticklabels([f"C{i}" for i in range(out_channels)])
    ax.set_title(f"Sample {sample_idx} Coefficient Comparison")
    ax.legend()
    return fig

N_test = Y_test_np.shape[0]
selected_indices = np.linspace(0, N_test - 1, 5, dtype=int)
for idx in selected_indices:
    i = int(idx)
    fig = plot_coefficients_comparison(Y_test_np[i], test_preds_np[i], i)
    fig.savefig(os.path.join(current_dir, f"test_coeffs_{i}.png"), dpi=300)
    plt.close(fig)

print("Training, validation, and test evaluation complete.")
print("Final Train MSE:", train_losses[-1])
print("Final Val MSE:", val_losses[-1])
print("Final Test MSE (final):", test_mse_final)
print("Five PNG files (each with ground truth and prediction coefficient comparisons) have been saved.")
